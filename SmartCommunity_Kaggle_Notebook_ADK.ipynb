{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7fd02ae",
   "metadata": {},
   "source": [
    "\n",
    "# SmartCommunity-AI — Kaggle Notebook (ADK + Gemini Integration)\n",
    "**Multi-agent Intelligent Concierge System** — single-file Kaggle-ready notebook configured to use **`gemini-1.5-flash-latest`** and `GOOGLE_API_KEY` as the credential.\n",
    "\n",
    "This notebook includes:\n",
    "- Project pitch & architecture\n",
    "- ADK/Gemini integration using `google.generativeai` (Gemini) for intent classification and agent reasoning\n",
    "- Multi-agent orchestrator (Orchestrator, ErrandAgent, MaintenanceAgent, InfoSearchAgent)\n",
    "- Tool integration examples (Vendor API mock, Google Search placeholder)\n",
    "- Demo cells to run locally in Kaggle (requires setting `GOOGLE_API_KEY` in Kaggle Secrets)\n",
    "\n",
    "---\n",
    "**Important:** Do not commit API keys. Use Kaggle Secrets (Settings → Secrets) to add `GOOGLE_API_KEY`. Replace mock tools with real APIs where commented.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8589fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install dependencies (uncomment if needed on Kaggle)\n",
    "# !pip install --quiet google-generativeai fastapi uvicorn python-dotenv requests\n",
    "\n",
    "print('If you need to install packages, uncomment the pip line above.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a5266c",
   "metadata": {},
   "source": [
    "\n",
    "## Configuration & Authentication\n",
    "\n",
    "Set the Kaggle secret `GOOGLE_API_KEY` (Kaggle → Settings → Secrets). This notebook reads it from `os.environ`.\n",
    "\n",
    "The notebook uses `google.generativeai` (the Google Generative AI Python client) to call Gemini Flash:\n",
    "- Model used: **`gemini-1.5-flash-latest`**\n",
    "\n",
    "You will also see placeholders for Vision model usage (commented) if you later want `gemini-1.5-pro-vision-latest` for image understanding tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bdba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, asyncio, logging, uuid, json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger('SmartCommunity-ADK')\n",
    "\n",
    "# Verify the API key is set\n",
    "API_KEY = os.environ.get('GOOGLE_API_KEY')\n",
    "if not API_KEY:\n",
    "    logger.warning('GOOGLE_API_KEY not found in environment. Set it in Kaggle Secrets before running Gemini calls.')\n",
    "else:\n",
    "    logger.info('GOOGLE_API_KEY found (not printed for security).')\n",
    "\n",
    "# Import the official Google Generative AI client (Gemini). If not installed, instruct user to install.\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    genai.configure(api_key=API_KEY)\n",
    "    logger.info('google.generativeai imported and configured.')\n",
    "except Exception as e:\n",
    "    logger.warning('google.generativeai is not available in this environment. Gemini calls will fail if attempted. %s', e)\n",
    "\n",
    "# NOTE: If Kaggle blocks direct outbound calls to Google endpoints you may need to run this locally or on Cloud Run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5ddf7a",
   "metadata": {},
   "source": [
    "\n",
    "## Notebook Overview (what each section does)\n",
    "\n",
    "1. Utility classes (MemoryBank, SessionService) — small in-memory stores for demo.  \n",
    "2. Tool wrappers — VendorAPI (mock), GoogleSearchTool (placeholder), Vision (optional).  \n",
    "3. Agents — ErrandAgent (sequential), MaintenanceAgent (loop/pause), InfoSearchAgent (parallel).  \n",
    "4. Orchestrator — routes user input using an intent classifier powered by Gemini Flash.  \n",
    "5. Demo — run sample interactions.  \n",
    "6. Guidance — how to replace mocks with real tools and deploy to Cloud Run / Vertex AI Agent Engine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce4219",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------- Utilities --------------------\n",
    "class MemoryBank:\n",
    "    def __init__(self):\n",
    "        self._prefs = defaultdict(dict)\n",
    "        self._interactions = defaultdict(list)\n",
    "\n",
    "    def get_preference(self, resident_id: str, key: str):\n",
    "        return self._prefs[resident_id].get(key)\n",
    "\n",
    "    def set_preference(self, resident_id: str, key: str, value):\n",
    "        self._prefs[resident_id][key] = value\n",
    "\n",
    "    def save_interaction(self, resident_id: str, summary: str):\n",
    "        self._interactions[resident_id].append(summary)\n",
    "        self._interactions[resident_id] = self._interactions[resident_id][-50:]\n",
    "\n",
    "    def get_recent(self, resident_id: str, n: int = 5):\n",
    "        return self._interactions[resident_id][-n:]\n",
    "\n",
    "\n",
    "class InMemorySessionService:\n",
    "    def __init__(self):\n",
    "        self._sessions = defaultdict(dict)\n",
    "\n",
    "    def get_session(self, resident_id: str):\n",
    "        return self._sessions[resident_id]\n",
    "\n",
    "    def update_session(self, resident_id: str, **kwargs):\n",
    "        self._sessions[resident_id].update(kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eacdc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------- Tools --------------------\n",
    "# VendorAPI: mock implementation. Replace with vendor OpenAPI client or real API calls.\n",
    "import requests\n",
    "\n",
    "class VendorAPI:\n",
    "    def __init__(self, base_url=None, api_key=None):\n",
    "        self.base = base_url or os.environ.get('VENDOR_API_URL', 'https://mock.vendor.api')\n",
    "        self.api_key = api_key or os.environ.get('VENDOR_API_KEY')\n",
    "\n",
    "    def list_vendors(self, category: str = 'grocery'):\n",
    "        # Replace with real HTTP call to vendors registry\n",
    "        return ['FreshMart', 'DailyNeeds', 'QuickShop']\n",
    "\n",
    "    def create_order(self, vendor: str, resident_id: str, items: list):\n",
    "        # Replace with real vendor order API call\n",
    "        return {'order_id': str(uuid.uuid4()), 'vendor': vendor, 'items': items}\n",
    "\n",
    "# GoogleSearchTool: placeholder that *could* use Programmable Search Engine (PSE) or SERP API.\n",
    "class GoogleSearchTool:\n",
    "    async def search(self, query: str) -> str:\n",
    "        # For demo, call Gemini to summarize search intent (or return mock snippet)\n",
    "        # In production, call PSE JSON API or a Search API, then summarize the results with Gemini.\n",
    "        await asyncio.sleep(0.1)\n",
    "        return f\"(simulated search snippet) Top results for: {query}\"\n",
    "\n",
    "# Vision tool placeholder (if you plan to use gemini vision model later)\n",
    "class VisionTool:\n",
    "    async def analyze_image(self, image_url: str) -> str:\n",
    "        # In production: send image to Vision model (gemini-vision) and return analysis\n",
    "        await asyncio.sleep(0.1)\n",
    "        return f\"(simulated) analyzed image at {image_url}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a862556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------- Agents (with Gemini integration) --------------------\n",
    "\n",
    "# Helper: call Gemini for intent classification or reasoning\n",
    "def call_gemini_chat(prompt: str, model: str = \"gemini-1.5-flash-latest\", temperature: float = 0.0, max_output_tokens: int = 512):\n",
    "    \"\"\"Call Gemini chat completion. Requires google.generativeai installed and GOOGLE_API_KEY set.\"\"\"\n",
    "    try:\n",
    "        # Use the Chat API to get a structured response. We pass a system message and user prompt.\n",
    "        response = genai.chat.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant for routing and decision-making in a residential concierge system.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=temperature,\n",
    "            max_output_tokens=max_output_tokens\n",
    "        )\n",
    "        # For the google.generativeai client, response may have 'candidates' or 'last'. We'll try common properties.\n",
    "        if hasattr(response, 'last'):\n",
    "            return str(response.last)\n",
    "        if isinstance(response, dict):\n",
    "            # Best-effort extract\n",
    "            if 'candidates' in response and len(response['candidates'])>0:\n",
    "                return response['candidates'][0].get('content', '')\n",
    "            if 'output' in response:\n",
    "                return str(response['output'])\n",
    "        return str(response)\n",
    "    except Exception as e:\n",
    "        logger.warning('Gemini call failed: %s', e)\n",
    "        return f\"(gemini_call_failed) {e}\"\n",
    "\n",
    "\n",
    "class ErrandAgent:\n",
    "    def __init__(self, vendor_api: VendorAPI, search_tool: GoogleSearchTool):\n",
    "        self.vendor_api = vendor_api\n",
    "        self.search = search_tool\n",
    "\n",
    "    async def run(self, resident_id: str, message: str, session: dict, memory: MemoryBank) -> str:\n",
    "        logger.info('ErrandAgent received: %s', message)\n",
    "        # 1) Use Gemini to extract structured order info (items, time, constraints)\n",
    "        prompt = f\"Extract structured order details from the user's request: '{message}'. Return JSON with keys: intent, items (list of {{item,qty}}), time, notes.\" \n",
    "        structured = call_gemini_chat(prompt)\n",
    "\n",
    "        # 2) Find vendors\n",
    "        vendors = self.vendor_api.list_vendors(category='grocery')\n",
    "\n",
    "        # 3) Price lookup (parallel)\n",
    "        async def price_lookup(vendor):\n",
    "            return await self.search.search(f\"{vendor} grocery prices near me\")\n",
    "\n",
    "        tasks = [price_lookup(v) for v in vendors[:3]]\n",
    "        prices = await asyncio.gather(*tasks)\n",
    "\n",
    "        # 4) Choose vendor using Gemini as a decision-maker (optional)\n",
    "        decision_prompt = f\"You are a decision agent. Given vendors: {vendors} and price snippets: {prices}, which vendor would you choose and why?\" \n",
    "        vendor_choice = call_gemini_chat(decision_prompt)\n",
    "\n",
    "        # Fallback: choose first vendor\n",
    "        chosen = vendors[0]\n",
    "        order = self.vendor_api.create_order(vendor=chosen, resident_id=resident_id, items=[{\"item\":\"milk\",\"qty\":1}])\n",
    "\n",
    "        reply = (\n",
    "            f\"Order placed with {chosen}. Order ref: {order['order_id']}\\n\"\n",
    "            f\"Vendor decision reasoning (Gemini): {vendor_choice}\\n\"\n",
    "            f\"Price snippets:\\n{chr(10).join(prices)}\"\n",
    "        )\n",
    "        return reply\n",
    "\n",
    "\n",
    "class MaintenanceAgent:\n",
    "    def __init__(self, vision_tool: VisionTool = None):\n",
    "        self.vision = vision_tool\n",
    "\n",
    "    async def run(self, resident_id: str, message: str, session: dict, memory: MemoryBank) -> str:\n",
    "        logger.info('MaintenanceAgent start for %s', resident_id)\n",
    "        if not session.get('awaiting_photo'):\n",
    "            session['awaiting_photo'] = True\n",
    "            return 'Please upload a photo of the damage so we can assess and assign a contractor.'\n",
    "\n",
    "        photo = session.get('damage_photo_url')\n",
    "        if not photo:\n",
    "            # In production use webhooks; here we wait briefly\n",
    "            for _ in range(6):\n",
    "                await asyncio.sleep(1)\n",
    "                photo = session.get('damage_photo_url')\n",
    "                if photo:\n",
    "                    break\n",
    "\n",
    "        if not photo:\n",
    "            return 'No photo received. We can escalate to a guard inspection if you prefer.'\n",
    "\n",
    "        # Use vision model via Gemini if available (placeholder)\n",
    "        analysis = None\n",
    "        if self.vision:\n",
    "            analysis = await self.vision.analyze_image(photo)\n",
    "        else:\n",
    "            # Or use Gemini text model to reason about the photo (pass image URL as text)\n",
    "            analysis_prompt = f\"A resident uploaded a photo at URL: {photo}. Provide a short assessment and categorize severity (low/medium/high).\"\n",
    "            analysis = call_gemini_chat(analysis_prompt)\n",
    "\n",
    "        ticket_id = f\"TKT-{resident_id[:4]}-{str(uuid.uuid4())[:6]}\"\n",
    "        session['last_ticket'] = ticket_id\n",
    "        preferred = memory.get_preference(resident_id, 'contractor') or 'on-call contractor'\n",
    "        return f\"Ticket {ticket_id} created. Analysis:\\n{analysis}\\nAssigned to {preferred}.\"\n",
    "\n",
    "\n",
    "class InfoSearchAgent:\n",
    "    def __init__(self, search_tool: GoogleSearchTool):\n",
    "        self.search = search_tool\n",
    "\n",
    "    async def run(self, resident_id: str, message: str, session: dict) -> str:\n",
    "        # Use search tool then optionally summarize with Gemini\n",
    "        results = await self.search.search(message)\n",
    "        # Summarize with Gemini\n",
    "        summary_prompt = f\"Summarize these search results concisely for a resident: {results}\"\n",
    "        summary = call_gemini_chat(summary_prompt)\n",
    "        return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d304fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------- Orchestrator --------------------\n",
    "class Orchestrator:\n",
    "    def __init__(self):\n",
    "        self.vendor_api = VendorAPI()\n",
    "        self.search_tool = GoogleSearchTool()\n",
    "        self.vision_tool = VisionTool()\n",
    "        self.errand_agent = ErrandAgent(self.vendor_api, self.search_tool)\n",
    "        self.maintenance_agent = MaintenanceAgent(self.vision_tool)\n",
    "        self.info_search_agent = InfoSearchAgent(self.search_tool)\n",
    "        self.sessions = InMemorySessionService()\n",
    "        self.memory = MemoryBank()\n",
    "\n",
    "    def classify_intent(self, message: str) -> str:\n",
    "        \"\"\"Use Gemini to classify intent into ERRAND, MAINTENANCE, INFO.\"\"\"\n",
    "        prompt = f\"Classify the following user message into one of: ERRAND, MAINTENANCE, INFO. Respond with a single token exactly. Message: '''{message}'''\"\n",
    "        cls = call_gemini_chat(prompt, max_output_tokens=20, temperature=0.0)\n",
    "        cls_token = cls.strip().split()[0] if cls else 'INFO'\n",
    "        return cls_token.upper()\n",
    "\n",
    "    async def handle_message(self, resident_id: str, message: str) -> str:\n",
    "        session = self.sessions.get_session(resident_id)\n",
    "        intent = self.classify_intent(message)\n",
    "        logger.info('Intent classified: %s', intent)\n",
    "\n",
    "        if intent == 'ERRAND':\n",
    "            result = await self.errand_agent.run(resident_id, message, session=session, memory=self.memory)\n",
    "        elif intent == 'MAINTENANCE':\n",
    "            result = await self.maintenance_agent.run(resident_id, message, session=session, memory=self.memory)\n",
    "        else:\n",
    "            info_task = asyncio.create_task(self.info_search_agent.run(resident_id, message, session=session))\n",
    "            quick_reply = \"I can help with errands, maintenance, and info. Which would you like?\"\n",
    "            info = await info_task\n",
    "            result = f\"{quick_reply}\\nAdditional info:\\n{info}\"\n",
    "\n",
    "        # compact context + store\n",
    "        summary = f\"Q:{message[:200]} | A:{str(result)[:300]}\"\n",
    "        self.memory.save_interaction(resident_id, summary)\n",
    "        self.sessions.update_session(resident_id, last_message=message)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe289874",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------- Demo --------------------\n",
    "import asyncio\n",
    "\n",
    "async def demo_flow():\n",
    "    orch = Orchestrator()\n",
    "    print('--- Errand example ---')\n",
    "    r1 = await orch.handle_message('res_001', 'Please buy 2 liters of milk and a loaf of bread tomorrow morning')\n",
    "    print(r1)\n",
    "\n",
    "    print('\\n--- Maintenance example (initial request) ---')\n",
    "    r2 = await orch.handle_message('res_001', 'There is a water leak in my bathroom, please check')\n",
    "    print(r2)\n",
    "\n",
    "    print('\\nSimulating photo upload to session...')\n",
    "    orch.sessions.update_session('res_001', damage_photo_url='https://example.com/damage.jpg')\n",
    "    r3 = await orch.handle_message('res_001', 'I have uploaded the photo')\n",
    "    print(r3)\n",
    "\n",
    "    print('\\n--- Info example ---')\n",
    "    r4 = await orch.handle_message('res_001', 'What time is the pharmacy open nearby?')\n",
    "    print(r4)\n",
    "\n",
    "# Run demo (only if this notebook has access to Gemini; otherwise the calls will fallback to warnings)\n",
    "try:\n",
    "    asyncio.get_event_loop().run_until_complete(demo_flow())\n",
    "except Exception as e:\n",
    "    print('Demo error:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece70758",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Next steps & deployment tips\n",
    "\n",
    "- Add the Kaggle secret `GOOGLE_API_KEY`. Run the demo section to see real Gemini-driven behavior.\n",
    "- Replace `VendorAPI` with your vendor OpenAPI client and secure API keys as Kaggle secrets.\n",
    "- For image analysis, integrate Gemini Vision (`gemini-1.5-pro-vision-latest`) and update `VisionTool.analyze_image` to call the Vision endpoint with image bytes/URL.\n",
    "- To deploy, containerize the notebook code (or modularized repo) and deploy to Cloud Run. Use Service Account key at deployment time or work with Workload Identity.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
